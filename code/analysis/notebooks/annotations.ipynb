{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotations of the workflow\n",
    "\n",
    "The idea is to get more content about the project/workflow.\n",
    "\n",
    "* Conda environment for this Notebook: [Greference_tools](../../environments/Greference_tools.yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libreries\n",
    "\n",
    "# Base packages\n",
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata/report.csv\n",
    "\n",
    "Lets see our Project and all the fields.\n",
    "\n",
    "For this project we will be interested in download the Bam files in the ***8 field***: **submitted_ftp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.read_csv(\"../../../metadata/report.tsv\", sep=\"\\t\")\n",
    "report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the table 3, for supporting information found in the article.\n",
    "\n",
    "After that we will use the function in pandas ```pd.read_clipboard()``` to download the data. \n",
    "\n",
    "You have to copy the table and run the function.\n",
    "\n",
    "https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fgcc.22314&file=gcc22314-sup-0005-supptable5.docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table3=pd.read_clipboard()\n",
    "table3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We wolud do some tranformations to the first field (\"Sample\")\n",
    "table3[\"Sample\"] = table3[\"Sample\"].str.replace(\n",
    "    \"-\", \"_\"\n",
    "    ).str.replace(\n",
    "        \"^\", \"_method1\"\n",
    "        ).str.replace(\n",
    "            \"*\", \"_method2\"\n",
    "            )\n",
    "table3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table3.to_csv(\"../../../metadata/table3.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table3_csv = pd.read_csv(\"../../../metadata/table3.csv\")\n",
    "table3_csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount of reads after removing low quality sequences. \n",
    "### Low quality sequences are considered when\n",
    "\n",
    "1. bases with Q20 account for >85% of the total sequence length \n",
    "2. reads with N-rate >10%\n",
    "\n",
    "### Methods for seguencing\n",
    "\n",
    "* **method1** run with Agilent Sureselect XT Human All Exon 50Mb\n",
    "* **method2** run with Agilent SureSelect_XT_Human_All_Exon_V5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean depth of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table3_csv[\"Sequencing depth (X)\"].str.replace(\",\",\".\").astype(float).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plot of the rules from the snakemake pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"python\", \"../scripts_analysis/workflow_viz.py\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    " \n",
    "  <img src=\"../results_analysis/plots/snakemake_rules_linear.png\" alt=\"600\" width=\"500\" />\n",
    "\n",
    "</p>\n",
    "\n",
    "Plot to show the structure to follow of the pipline\n",
    "\n",
    "* Color *green*: you have to execute **multiple** times this rule (as much chromosomes/genes you want to filter).\n",
    "\n",
    "* Color *orange*: you have to execute only **1** time, the first run of the workflow.\n",
    "\n",
    "* Color *red*: you have to execute only **1** time, the last run, after having all genes filter tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Calculating the AVERAGE sequence length for each sample**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## heavy computing +25 min -> you need all fastq.gz files in data/raw/\n",
    "\n",
    "for chr in [\"chr3\", \"chr5\", \"chr7\", \"chr12\", \"chr17\"]:\n",
    "    subprocess.run([\"bash\", \"../scripts_analysis/01calculating_length.sh\", chr])\n",
    "\n",
    "subprocess.run([\"bash\", \"../scripts_analysis/02joining_files.sh\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = os.listdir(\"../../../results/annotations/\")\n",
    "\n",
    "list_files_path = []\n",
    "\n",
    "for file in range(len(list_files)):\n",
    "    path = \"../../../results/annotations/\" + list_files[file]\n",
    "    list_files_path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mean_len = []\n",
    "list_sd_len = []\n",
    "\n",
    "for file_path in list_files_path:\n",
    "\n",
    "    with open(file_path) as file:\n",
    "        len_list = file.readlines()\n",
    "    \n",
    "    mean_seq_len = np.array([s.strip() for s in len_list]).astype(int).mean().round(2)\n",
    "    sd_seq_len = np.array([s.strip() for s in len_list]).astype(int).std().round(2)\n",
    "    \n",
    "    print(\"mean value of \", file_path.replace(\n",
    "        \"../../../results/annotations/\", \"\"\n",
    "        ).replace(\n",
    "            \"_len.txt\", \"\"\n",
    "            ), \" -> \", mean_seq_len, \"+/-\", sd_seq_len)\n",
    "\n",
    "    list_mean_len.append(mean_seq_len)\n",
    "    list_sd_len.append(sd_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_len_seq = pd.DataFrame({\n",
    "    \"sample\": pd.Series(list_files_path),\n",
    "    \"mean_len\": pd.Series(list_mean_len),\n",
    "    \"sd_len\": pd.Series(list_sd_len)\n",
    "})\n",
    "\n",
    "df_len_seq[\"sample\"] = df_len_seq[\"sample\"].str.replace(\"../../results/annotations/\", \"\")\n",
    "df_len_seq[\"sample\"] = df_len_seq[\"sample\"].str.replace(\"_len.txt\", \"\")\n",
    "\n",
    "df_len_seq.to_csv(\"../results_analysis/tables/len_mean.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"Rscript\", \"../scripts_analysis/03plot_mean_len.R\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Number of Seqs before and after fastp**\n",
    "\n",
    "* In order to run the next code, you have to have all fastq files (**all chromosomes, reads**) in *raw* and *processed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"bash\", \"../scripts_analysis/04fastp_analysis.sh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fastp = pd.read_csv(\"../results_analysis/tables/fastp_analysis.tsv\", sep=\"\\t\")\n",
    "df_fastp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapped reads, with the reference Genome\n",
    "\n",
    "* ### flagstats: in order to do this analysis, you need all the flagstats information in metadata/logs/flagstats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"bash\", \"../scripts_analysis/05flagstats.sh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagstats = pd.read_csv(\"../results_analysis/tables/flagstats.tsv\", sep=\"\\t\")\n",
    "flagstats[\"mapped_reads_per\"] = np.array(flagstats.mapped_reads/flagstats.num_seqs_afterQC*100).round(2)\n",
    "flagstats[\"properly_paired_per\"] = np.array(flagstats.properly_mapped/flagstats.num_seqs_afterQC*100).round(2) \n",
    "flagstats[\"singletons_per\"] = np.array(flagstats.singletons/flagstats.num_seqs_afterQC*100).round(2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagstats.to_csv(\"../results_analysis/tables/flagstats.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the previous table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"Rscript\", \"../scripts_analysis/06plot_flagstats.R\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VCF stats\n",
    "\n",
    "* For this analysis you'll need all the files created in the dir metadata/logs/vcfstats  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"bash\", \"../scripts_analysis/07vcfstats.sh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process additional vcf stats \n",
    "vcf_stats = pd.read_csv(\"../results_analysis/tables/additional_vcf_stats.tsv\", sep=\"\\t\", index_col=False)\n",
    "vcf_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for col in vcf_stats.iloc[:,:9].columns:\n",
    "    new_cols.append(\"r_\" + col)\n",
    "\n",
    "print(new_cols)\n",
    "\n",
    "for name,ncol in zip(new_cols, range(len(vcf_stats.columns) -1)):\n",
    "    vcf_stats[name] = vcf_stats.iloc[:,ncol].str.split(\"|\").apply(lambda x: float(x[0]) / float(x[1])).round(2)\n",
    "\n",
    "vcf_stats\n",
    "\n",
    "ratios_vstats = vcf_stats.iloc[:,9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in vcf_stats.iloc[:,:9]:\n",
    "    vcf_stats[name] = \"(\" + vcf_stats[name].str.replace(\"|\", \"/\") + \")\"\n",
    "    \n",
    "for name,r_name in zip(vcf_stats.iloc[:,:9].columns, vcf_stats.iloc[:,10:].columns):\n",
    "    vcf_stats[name] = vcf_stats[r_name].astype(str) + \" \" + vcf_stats[name]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_stats = vcf_stats.iloc[:,:10]\n",
    "\n",
    "vcf_stats.to_csv(\"../results_analysis/tables/additional_vcf_stats.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_vstats.to_csv(\"../results_analysis/tables/ratios_vcfstats.tsv\", sep=\"\\t\")\n",
    "ratios_vstats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"Rscript\", \"../scripts_analysis/08ploting_vcfstats.R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statisticall analysis from the last plot\n",
    "subprocess.run([\"Rscript\", \"../scripts_analysis/09statistical_analysis.R\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
